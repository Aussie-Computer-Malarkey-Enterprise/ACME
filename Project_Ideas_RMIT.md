#### 30 August 2016 at 21:14 (3 hours ago)
I want to propose that our project involve [brain–computer interfaces](https://en.wikipedia.org/wiki/Comparison_of_consumer_brain%E2%80%93computer_interfaces).

I will now try to think of how to use this technology for a project; but I would like suggestions! ;-)

Unfortunately it is expensive, so that should be taken into consideration; maybe this isn't such a good idea?

http://store.neurosky.com/
<br>MindWave costs $79.99 USD, which is approximately $105.94 AUD, and comes with 10 apps; it should be all we need for a project.

#### 30 August 2016 at 21:30 (3 hours ago)
I might suggest some more economical options...

[Algorithms](https://en.wikipedia.org/wiki/List_of_algorithms)

[Applicable Functionality](https://en.wikipedia.org/wiki/Outline_of_software)

[Artificial Intelligence](https://en.wikipedia.org/wiki/Progress_in_artificial_intelligence)

#### 30 August 2016 at 21:42 (3 hours ago)
I was thinking of quantising the neural patterns. So if the system prompts the user, it could be a simple binary decision for yes/no, for example; or a ternary decision for yes/no/maybe...

The interface could just be to move the cursor in a specific direction and keep it in that area of the screen, or something; I don't know how the interface works, or how to control things mentally, but it definitely has been held in my interest for many years now!

I tend to put things off if they cost money; but if I have someone to work with, then it's a lot more motivating, and worth the investment.

#### 30 August 2016 at 21:55 (2 hours ago)
I would like to do a project that involves concurrency/parallelism (multi-core / distributed computing)

We should think in terms of [domains](https://en.wikipedia.org/wiki/Programming_domain).

#### 30 August 2016 at 23:53 (56 minutes ago)
Some more places to look for inspiration:
<br>‣ [Technology](https://en.wikipedia.org/wiki/Template:Technology)
<br>‣ [Emerging Technology](https://en.wikipedia.org/wiki/Template:Emerging_technologies)
<br>‣ [Fictional Technology](https://en.wikipedia.org/wiki/Fictional_technology)

We could do something with [Stereoscopy](https://en.wikipedia.org/wiki/Template:Stereoscopy):
<br>‣ [Autostereograms](https://en.wikipedia.org/wiki/Autostereogram); search for "3D Sterogram Tetris", that's something I was looking into a few years back.
<br>‣ [Anagliph 3D](https://en.wikipedia.org/wiki/Anaglyph_3D#Anaglyphic_color_channels); the link is to the various colour channels, we could write a conversion app, for example.

I'm interested in [3D reconstruction](https://en.wikipedia.org/wiki/3D_reconstruction).
<br>Imagine any number of microphones (okay maybe it needs >1 for triangulated depth perception).
<br>[Echolocation](https://en.wikipedia.org/wiki/Echolocation) c̄ 1+ℤ microphones.
<br>And using the auditory feedback to paint a 3D visualisation.
<br>It involves the triangulation of multiple microphones for orientation determination.
<br>I want to be able to fly around in the 3D representation.
<br>This has low costs, but the costs do exists (for those of us who do not possess microphones; but we will be required to obtain at least 2 for the project).
<br>Think of each microphone as a satellite, and the 3D environment surrounding the microphones as the observable universe, and the sound waves as photonic emanations from star systems...

[Binaural Beats](https://en.wikipedia.org/wiki/Binaural_beats) is another fascination I have.

And then there's multiphasic [spectral analysis](https://en.wikipedia.org/wiki/Spectral_analysis)...

\<afterthought: one_microphone("order in a circular fashion as received"), two_microphones("decide based on nearby results, should be smooth, connect the dots", "can find the location of the microphones by initial wave for distance, and use the echo for location"), sound_waves("inaudible frequencies", "alternating throughout the ranges to avoid conflicts of interest", "only time will tell the distance")\>

#### 31 August 2016 at 00:00 (49 minutes ago)
My attempt at exhausting all possibilities is probably futile..?

[A big world of small motions | Michael Rubinstein | TEDxYouth@BeaconStreet](https://youtu.be/fenV3W7hQtw)

[Michael Rubinstein: See invisible motion, hear silent sounds. Cool? Creepy? We can't decide](https://youtu.be/fHfhorJnAEI)

[Abe Davis: New video technology that reveals an object's hidden properties](https://youtu.be/npNYP2vzaPo)

#### 31 August 2016 at 00:06 (43 minutes ago)
I'm not sure if [Linux From Scratch](https://en.wikipedia.org/wiki/Linux_From_Scratch) would be a valid project; I have my doubts...

#### 31 August 2016 at 00:25 (24 minutes ago)
I'm sure we could write a [transcompiler](https://en.wikipedia.org/wiki/Source-to-source_compiler#Programming_language_implementations), as long as the source-target combination isn't included in the list that I linked to.

We could write something based on a [GNU package](https://en.wikipedia.org/wiki/List_of_GNU_packages); there are many to choose from!

We could write a [language shell](https://en.wikipedia.org/wiki/Read%E2%80%93eval%E2%80%93print_loop); sort of like a generalised version of [repl.it](https://repl.it/languages), or something of the like...

[Syntax highlighting](https://en.wikipedia.org/wiki/Syntax_highlighting) is a useful way to learn a language; or a parser, assembler, compiler, interpreter, et cetera...

Here are some things that I plan on developing: [ACME](https://github.com/Aussie-Computer-Malarkey-Enterprise/ACME)

#### 31 August 2016 at 00:32 (17 minutes ago)
This is my old failed student group: [RMIT OUA Bachelor Of Technology Students](https://github.com/ROBOTS-WAREZ)

The WebLog was somebody elses idea, but they didn't want to contribute; I was trying to plan out some kind of design with them, but they just kept telling me to start writing code...I kind of feel like they were just trolling me.

#### 31 August 2016 at 00:33 (16 minutes ago)
I'm going to add all of this to ACME; one of these days I'll get around to all of it...

#### 31 August 2016 at 13:20 (4 days ago)
The BCI project I proposed is just like the LEAP project; but using brainwaves, instead of gestures.

The echolocation project I proposed is just like the 3D Spatio-temporal Visualisation project; but using ordinary microphones and the sound waves they measure, instead of arbitrary "big data" from somewhere in the clouds.

\<afterthought: those LEAP gestures may be sound waves?\>

#### 31 August 2016 at 14:31 (4 days ago)
The echolocation project could be done with Python for all I care; all it requires is to interface with the microphones, and process the signal just like submarines perform echolocation using Sonar, for which I am sure there are readily available algorithms for us to take advantage of.

#### 31 August 2016 at 15:04 (4 minutes ago)
KK.

Here are some more resources to consider...

[Draft Programming Tasks](http://rosettacode.org/wiki/Category:Draft_Programming_Tasks) (tasks that are underdeveloped)
<br>[Programming Tasks](https://rosettacode.org/wiki/Category:Programming_Tasks) (tasks that are well-defined with solutions)

[Other websites](http://rosettacode.org/wiki/Help:Similar_Sites) besides RosettaCode.Org

Tools:
<br>[Collaborative Coding](https://codeshare.io/)
<br>[Linguistic Exercises](https://rosettacode.org/wiki/Category:Simple)
